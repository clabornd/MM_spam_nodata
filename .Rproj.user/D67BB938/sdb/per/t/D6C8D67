{
    "collab_server" : "",
    "contents" : "stop_titles <- c(\"mr. \",\n                 \"mrs. \",\n                 \"dr. \",\n                 \"md. \",\n                 \"ms \")\nroate_text <- function(a) {\n  theme(axis.text.x = element_text(angle = a, hjust = 1))\n}\n\n\n#get occurences of words within messages for unique email id's\nget_counts_unique <- function(df, message_col, multinomial = FALSE, ngrams = FALSE){\n  quo_col <- enquo(message_col)\n\n  if(multinomial){\n    frame <- df %>%\n      select(!!quo_col) %>%\n      unnest_tokens(token, message, token = \"words\") %>%\n      anti_join(stop_words, by = c(\"token\"=\"word\")) %>%\n      group_by(token) %>%\n      mutate(n = n()) %>%\n      distinct(token, n)\n\n    if(ngrams){\n      rbind(frame,\n            df %>%\n              select(!!quo_col) %>%\n              unnest_tokens(token, message, token = \"ngrams\", n =2) %>%\n              group_by(token) %>%\n              mutate(n = n()) %>%\n              distinct(token, n)\n      )\n    }\n\n    frame\n\n  }\n\n  else{\n    frame <- df %>%\n      select(id_1, message) %>%\n      unnest_tokens(token, message, token = \"words\") %>% select(id_1, token) %>%\n      anti_join(stop_words, by = c(\"token\"=\"word\")) %>%\n      group_by(id_1) %>%\n      distinct(token) %>%\n      group_by(token) %>%\n      mutate(n = n()) %>%\n      distinct(token, n)\n\n    if(ngrams){\n      rbind(frame,\n            df %>%\n              select(id_1, message) %>%\n              unnest_tokens(token, message, token = \"ngrams\", n =2) %>%\n              group_by(id_1) %>%\n              distinct(token) %>%\n              group_by(token) %>%\n              mutate(n = n()) %>%\n              distinct(token, n)\n      )\n    }\n\n    frame\n\n  }\n}\n\nget_prob_tables <- function(spam_train, ham_train, multinomial = FALSE, ngrams = FALSE){\n  #word counts for both groups\n  word_counts_spam <- get_counts_unique(spam_train, message, multinomial, ngrams)\n  word_counts_ham <- get_counts_unique(ham_train, message, multinomial, ngrams)\n\n  allterms <- data.frame(token = unique(c(word_counts_spam$token, word_counts_ham$token))) %>%\n    mutate(token = as.character(token))\n\n  ###Posterior probabilities for each term given the document is spam or ham###\n  prob_table_spam <- allterms %>% left_join(word_counts_spam, by = \"token\") %>%\n    mutate(n = replace(n, is.na(n), 0), n = n + 1)\n\n  prob_table_ham <- allterms %>% left_join(word_counts_ham, by = \"token\") %>%\n    mutate(n = replace(n, is.na(n), 0), n = n + 1)\n\n  if(multinomial){\n    prob_table_spam <- prob_table_spam %>% mutate(logprob = log(n/sum(n)))\n    prob_table_ham <- prob_table_ham %>% mutate(logprob = log(n/sum(n)))\n  }\n  else{\n    prob_table_spam <- prob_table_spam %>% mutate(logprob = log(n/nrow(spam_train)))\n    prob_table_ham <- prob_table_ham %>% mutate(logprob = log(n/nrow(ham_train)))\n  }\n\n  list(prob_table_spam, prob_table_ham)\n\n}\n\n#test the model given a spam and ham table.\ntest_model <- function(test_emails, spam_table, ham_table, ngrams = FALSE, multinomial = FALSE, prior_ham = 0.5, prior_spam = 0.5){\n\n  test_emails[\"pred\"] <- 0\n\n  for(i in 1:nrow(test_emails)){\n\n    if(multinomial){\n      ###multinomial code\n\n      test_mail <- unnest_tokens(test_emails[i,], token, message) %>%\n        select(token) %>%\n        anti_join(stop_words, by = c(\"token\"=\"word\")) %>%\n        ungroup()\n\n      if(ngrams){\n        test_mail <- rbind(test_mail,\n                           unnest_tokens(test_emails[i,], token, message, token = \"ngrams\", n = 2) %>%\n                             select(token) %>%\n                             group_by(token) %>%\n                             ungroup()\n        )\n      }\n    }\n\n    else{\n\n      ###binary code\n      test_mail <- unnest_tokens(test_emails[i,], token, message) %>%\n        select(token) %>%\n        unique() %>%\n        anti_join(stop_words, by = c(\"token\"=\"word\")) %>%\n      if(ngrams){\n\n        test_mail <- rbind(test_mail,\n                           unnest_tokens(test_emails[i,], token, message, token = \"ngrams\", n = 2) %>%\n                             select(token) %>%\n                             unique())\n      }\n\n    }\n\n\n\n    ###should be same for both\n    log_prob_ham <- log(prior_ham) +\n      sum((test_mail %>%\n             left_join(ham_table, by = \"token\") %>%\n             mutate(logprob = replace(logprob, is.na(n), min(logprob))))$logprob)\n\n    log_prob_spam <- log(prior_spam) +\n      sum((test_mail %>%\n             left_join(spam_table, by = \"token\") %>%\n             mutate(logprob = replace(logprob, is.na(n), min(logprob))))$logprob)\n\n\n    if(log_prob_spam > log_prob_ham){\n      test_emails[i,]$pred <- 1\n    }\n\n  }\n\n  test_emails\n\n}\n",
    "created" : 1508277975421.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4148568957",
    "id" : "D6C8D67",
    "lastKnownWriteTime" : 1507752267,
    "last_content_update" : 1507752267,
    "path" : "C:/Users/interns/Desktop/MM-GIT/R/missing_tokens_functions.R",
    "project_path" : "R/missing_tokens_functions.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}